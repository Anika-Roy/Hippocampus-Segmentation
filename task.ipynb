{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks:\n",
    "1. Find a proper train test split\n",
    "2. Implement a model for the segmentation task.\n",
    "    - Find a proper loss function & explain the choice\n",
    "    - Provide the implementation of the model architecture, dataloader & training method\n",
    "    - Show that your implementation is working - one or two epochs are enough\n",
    "\n",
    "3. Extend your pipeline to create a flip-robust segmentation\n",
    "    - Add a second loss function, explain why this can be helpful and explain your choice\n",
    "    - Add a flip augmentation\n",
    "    - Show that your implementation is working - again one or two epochs are fine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the datasets: (source : Continual Hippocampus Segmentation with Transformers)\n",
    "1. Dryad: contains 50 cases of healthy patients\n",
    "2. HarP: The Harmonized Hippocampal Protocol dataset, which we refer to as HarP, contains healthy subjects and patients with Alzheimerâ€™s disease.\n",
    "\n",
    "I will be using the Dryad dataset for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import glob\n",
    "import nibabel as nib\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess data for a single case\n",
    "def load_and_preprocess_case(data_dir, case_name):\n",
    "    # Construct the file paths for image and mask\n",
    "    image_file = os.path.join(data_dir, f\"{case_name}.nii.gz\")\n",
    "    mask_file = os.path.join(data_dir, f\"{case_name}_gt.nii.gz\")\n",
    "    \n",
    "    # Load MRI image data\n",
    "    img_data = nib.load(image_file).get_fdata()\n",
    "    \n",
    "    # Load the corresponding ground truth segmentation mask\n",
    "    mask_data = nib.load(mask_file).get_fdata()\n",
    "    \n",
    "    # Preprocess data as needed (e.g., resize, normalize)\n",
    "    # You may need to adapt this preprocessing based on your data\n",
    "    \n",
    "    return img_data, mask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess the entire dataset\n",
    "def load_and_preprocess_dataset(dataset_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through each case name\n",
    "    case_names = [f\"s{str(i).zfill(2)}_{hemi}\" for i in range(1, 26) for hemi in ['L', 'R']]\n",
    "    \n",
    "    for case_name in case_names:\n",
    "        img_data, mask_data = load_and_preprocess_case(dataset_dir, case_name)\n",
    "        \n",
    "        if img_data is not None and mask_data is not None:\n",
    "            data.append(img_data)\n",
    "            labels.append(mask_data)\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the \"Dryad\" dataset directory\n",
    "dryad_dataset_dir = 'datasets/Dryad'\n",
    "\n",
    "# Load and preprocess the \"Dryad\" dataset\n",
    "dryad_data, dryad_labels = load_and_preprocess_dataset(dryad_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# print dryad_data and dryad_labels\n",
    "print(len(dryad_data))\n",
    "print(len(dryad_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (392324777.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    # Define your model architecture here\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Define your model architecture (e.g., U-Net)\n",
    "class UNet(nn.Module):\n",
    "    # Define your model architecture here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom dataset class for loading and preprocessing data\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'image': self.data[idx], 'mask': self.labels[idx]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Dice loss function\n",
    "def dice_loss(pred, target):\n",
    "    intersection = torch.sum(pred * target)\n",
    "    union = torch.sum(pred) + torch.sum(target)\n",
    "    dice = (2 * intersection) / (union + 1e-5)  # Add epsilon for numerical stability\n",
    "    return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# Initialize your model\n",
    "model = UNet()\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = dice_loss  # You can use BCE loss as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        inputs, masks = batch['image'].to(device), batch['mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, masks = batch['image'].to(device), batch['mask'].to(device)\n",
    "        outputs = model(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
